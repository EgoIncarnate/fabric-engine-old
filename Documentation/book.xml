<?xml version='1.0' encoding='UTF-8'?>
<article xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink"
  xmlns:xi="http://www.w3.org/2001/XInclude" xmlns:svg="http://www.w3.org/2000/svg"
  xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:html="http://www.w3.org/1999/xhtml"
  xmlns:db="http://docbook.org/ns/docbook" version="5.0">
  <info>
    <title>Fabric Engine SceneGraph Documentation</title>
    <copyright>
      <year>2012</year>
      <holder>Fabric Engine Inc.</holder>
    </copyright>
    <author>
      <personname>
        <firstname>Helge</firstname>
        <surname>Mathee</surname>
      </personname>
      <affiliation>
        <orgname>Fabric Engine Inc.</orgname>
        <address>
          <email>helge.mathee@fabric-engine.com</email>
        </address>
      </affiliation>
    </author>
  </info>
  <section>
    <title>Introduction</title>
    <section>
      <title>What's Fabric Engine's SceneGraph?</title>
      <para>The <emphasis role="bold">SceneGraph</emphasis> is a wrapper for its counterpart, the
        Fabric Engine Core. Fabric Engine's core is a very low level system, providing the core
        objects such as a <emphasis role="bold">Dependency Graph Node</emphasis>, <emphasis
          role="bold">Operators</emphasis> and other elements. The <emphasis role="bold"
          >SceneGraph</emphasis> however is an abstraction layer for the core. It provides <emphasis
          role="italic">presets</emphasis> for Dependency Graph Node setups, called the
        SceneGraphNodes. The SceneGraph is purely implemented in JavaScript, and therefore can be
        customized easily for any specialized purpose.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_introduction_01.png" width="40%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The SceneGraph is a factory which is used to create SceneGraphNodes. Each type of
        SceneGraphNode is registered with the SceneGraph on load. The factory function is
        responsible for constructing the underlying dependency graph, and returning an public
        interface. All data associated with the scene graph node is contained in the closure defined
        by the factory function. </para>
      <para>A good understanding of closures and how they work in JavaScript is essential for
        understanding the Fabric SceneGraph.</para>
      <para>The SceneGraph is provided as a series of JavaScript files which implement factory
        functions for a certain usage field, for example the file <emphasis role="italic"
          >Images.js</emphasis> contains several factory functions implementing 2D images, 3D images
        and video SceneGraphNodes.</para>
      <para>SceneGraphNodes encapsulate the core objects necessary to provide a certain
        functionality. The VideoNode, for example, contains the Dependency Graph Nodes to store all
        of the video related data, as well as all of the Operators to read and manipulate the video
        stream. Moreover it provides JavaScript functions to access and manipulate the video. </para>
      <para>SceneGraphNodes that don't contain any Dependency Graph Node, and are used mainly to
        provide utility functionality, are called <emphasis role="bold">Managers</emphasis>. One
        example of a manager is the UndoManager.</para>
      <para>The SceneGraph furthermore provides graphical utilities, such as the <emphasis
          role="bold">Debugger</emphasis>, which allows to inspect the constructed core Dependency
        Graph, and other tools, for example the <emphasis role="bold">Curve Editor</emphasis>, which
        allows to inspect and edit FCurve animation.</para>
    </section>
    <section>
      <title>Abstraction of the Dependency Graph</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_introduction_02.png" width="75%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The goal of the SceneGraph layer is to present an interface to developers focused on
        SceneGraph construction. The interfaces exposed follow common SceneGraph conventions. </para>
      <para>SceneGraphs can be setup in a few lines of code, and provide a rich array of features,
        from shader management and rendering, to manipulation and animation.</para>
      <para>The SceneGraph is written entirely in JavaScript, and it abstracts the notion of the
        dependency graph away from the user. The JavaScript code assembles a lower level dependency
        graph. </para>
    </section>
    <section>
      <title>Scene Object and SceneGraphNode Construction</title>
      <para>The <emphasis role="bold">scene</emphasis> object is the accessor for the SceneGraph
        factory, and is used to construct any SceneGraphNode.</para>
      <para>
        <programlisting>var scene = FABRIC.SceneGraph.createScene();</programlisting>
      </para>
      <para>The first SceneGraph object to be constructed is usually the scene object. The scene
        object creates a Fabric dependency graph context, a dependency graph node for containing
        globals, and some event handlers that are used in rendering. It returns an interface for
        constructing SceneGrapNodes. </para>
      <para>All SceneGraphNodes implemented in the SceneGraph are registered by providing their type
        as well as a constructor function. A node of a registered type can be constructed by using
        JavaScript like this:</para>
      <para>
        <programlisting>var sgNode = scene.constructNode('Image2D', { name: 'myImageNode' } );</programlisting>
      </para>
      <para>The options supported by each SceneGraphNode can be found in the following chapters,
        respectively in the <emphasis role="bold">SceneGraphNode Reference</emphasis> of this
        document. </para>
    </section>
    <section>
      <title>Public and Private Interfaces</title>
      <para>SceneGraphNodes provide a private as well as a public interface. Outside of constructor
        functions it's only possible to access the public interface, while inside of constructor
        functions it's possible to access the private interface. This allows to include helper
        functions in the each node, such as setter functions for private members for example, that
        are only accessible in constructor functions of other nodes. Since the options used for the
        construction of a node can contain references to a public interface, you can retrieve the
        private interface by using this call:</para>
      <programlisting>var privateInterface = scene.getPrivateInterface(publicInterface);</programlisting>
      <para>To access the public interface from a private one, you simply need to access the
          <emphasis role="italic">.pub</emphasis> member of the private interface.<emphasis
          role="bold"> </emphasis>Managers can also access private interfaces, allowing them to
        perform changes to the private data, for example.</para>
      <programlisting language="JavaScript">var sgNode = {
  pub: {
    publicMethod: function () {}
  },
  privateMethod: function () {}
};</programlisting>
    </section>
    <section>
      <title>Custom SceneGraphNodes and Inheritance</title>
      <para>Applications can register their own, custom SceneGraphNodes. This can be useful and
        necessary when extending an existing node, for example, or providing a completely new one.
        Inside the constructor function of the custom node all other nodes can be accessed through
        their private interfaces, allowing to modify and access the inner workings of the
        SceneGraph. Extending the private or the public interface allows to inherit features of
        another SceneGraphNode. It is also possible to override an existing function on each
        interface by simply setting it to different function inside the custom node's constructor.
        For further details refer to the tutorials sections of this document.</para>
    </section>
    <section>
      <title>The SceneGraph Debugger</title>
      <mediaobject>
        <imageobject>
          <imagedata fileref="images/sg_debugger_01.png" width="100%"/>
        </imageobject>
      </mediaobject>
      <para>The debugger is a useful tool to inspect the dependency graph contructed by the
        SceneGraph. Especially when building custom SceneGraphNodes this can be very helpful. The
        debugger is described in more detail in the section on the Drawing Pipeline Guide in this
        document. You can open the debugger by using executing this code in JavaScript:</para>
      <programlisting language="JavaScript">FABRIC.displayDebugger();</programlisting>
    </section>
  </section>
  <section role="">
    <title>SceneGraph Type System</title>
    <para>Fabric Engine can work with any type of data. To define the structure of data, you need to
      introduce <emphasis role="bold">Types</emphasis>. Types are very similar to structs in C++.
      Core types, such as <emphasis role="bold">Integer</emphasis>, <emphasis role="bold"
        >Boolean</emphasis> or <emphasis role="bold">String</emphasis> are defined by the core. More
      complex types, such as the <emphasis role="bold">Vec3</emphasis>, for example, are defined by
      the SceneGraph.</para>
    <section>
      <title>Querying types</title>
      <para>You can access all of the currently registered types, by calling on the <emphasis
          role="bold">RegisteredTypesManager</emphasis>. The manager is only accessible in the scope
        of a SceneGraphNode factory function, but you can access a dictionary of all current types
        by accessing the <emphasis role="bold">RT</emphasis> object:</para>
      <programlisting language="JavaScript">console.log(FABRIC.RT);</programlisting>
      <para>Types are typically implemented in separate JavaScript files. The ones provided by the
        SceneGraph can be found in the RT directory. The SceneGraph uses a <emphasis role="bold"
          >require</emphasis> framework which ensures that all required scripts are automatically
        included into the application. You can find more details about this in the tutorials section
        of this document, covering the creation of a custom SceneGraphNode.</para>
    </section>
    <section>
      <title>JavaScript and KL</title>
      <para>Types can provide extra functionality both in JavaScript as well as Fabric Engine's
        kernel language (<emphasis role="bold">KL</emphasis>). The type below implements an
          <emphasis role="bold">Address</emphasis>, and implements both a JavaScript file as well as
        a KL file providing the additional functions, called the <emphasis role="bold"
          >bindings</emphasis>. The content of the JavaScript file looks like this: (the first array
        parameter is the list of requirements. this could include other types, for example.)</para>
      <programlisting language="JavaScript">FABRIC.define([], function() {

  // Constructor:
  FABRIC.RT.Address = function(options) {
    if(!options) options = {};
    this.street = options.street != undefined ? options.street : '';
    this.number = options.number != undefined ? options.number : 1;
    this.city = options.city != undefined ? options.city : '';
    this.zip = options.zip != undefined ? options.zip : 1000;
    this.country = options.country != undefined ? options.country : '';
  };
  
  // Prototype, providing additional methods
  FABRIC.RT.Address.prototype = {
    getPrintable: function() {
      return this.street + ' ' + this.number + ' in ' + this.zip + ' ' + this.city + ', ' + this.country;
    }
  };
  
  // Append this type to be loaded once the Fabric context exists
  FABRIC.appendOnCreateContextCallback(function(context) {
    context.RegisteredTypesManager.registerType('Address', {
      members: {
        street: 'String', number: 'Integer', city: 'String', zip: 'Integer', country: 'String'
      },
      constructor: FABRIC.RT.Address,
      klBindings: {
        filename: 'Address.kl',
        sourceCode: FABRIC.loadResourceURL('RT/Address.kl')
      }
    });
  });

  return FABRIC.RT.Address;
});</programlisting>
      <para>The KL file mentioned in the appendOnCreateContextCallback above, <emphasis role="bold"
          >RT/Address.kl</emphasis> could look like this:</para>
      <programlisting language="JavaScript">function String Address.getPrintable() {
  return this.street + ' ' + this.number + ' in ' + this.zip + ' ' + this.city + ', ' + this.country;
}</programlisting>
      <para>This will make the <emphasis role="bold">getPrintable</emphasis> method available both
        in JavaScript as well as in KL. As you can see, you can specify any type of data. You can of
        course include custom types as members of other custom types, and therefore build very
        complex structures, which then can be used for computation inside the dependency graph or
        MapReduce.</para>
    </section>
  </section>
  <section>
    <title>Kinematics Guide</title>
    <section>
      <title>Basic Transform</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_kinematics_01.png" width="45%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The SceneGraph's basic transform can represent a global or a hierarchical transform. It
        can be contructed like this:</para>
      <programlisting language="JavaScript">var globalTransform = scene.constructNode('Transform', {
  hierarchical: false
});
var hierarchicalTransform = scene.constructNode('Transform', {
  hierarchical: true,
  parentTransformNode: globalTransform
});</programlisting>
      <para>When contructed in global mode (hierarchical: false), the transform simply uses a global
        matrix. When contructed in hierarchical mode, the construction options need to contain a
        parent transform. An operator will be attached to the transform node, which computes the
        global matrix based on the parent as well as a local matrix. This way hierarchies of
        transforms can be constructed.</para>
      <para>When creating the transform node, you can specify the global resp. the local matrix by a
          <emphasis role="bold">FABRIC.RT.Xfo</emphasis>, like this:</para>
      <programlisting language="JavaScript">var globalTransform = scene.constructNode('Transform', {
  hierarchical: false,
  globalXfo: new FABRIC.RT.Xfo({
    tr: new FABRIC.RT.Vec3(1.0, 2.0, 3.0)
  })
});</programlisting>
    </section>
    <section>
      <title>Aimed Transform</title>
      <para>For the typical <emphasis role="italic">lookat</emphasis> behaviour of a transform, for
        example used for a camera with an lookat position, or a spot light with a target position,
        the SceneGraph provides a specialized transform node called the <emphasis role="bold"
          >AimTransform</emphasis>. It adds an additional option to the factory function, which
        allows you to specify the target position.</para>
      <programlisting language="JavaScript">var aimTransform = scene.constructNode('AimTransform', {
  globalXfo: new FABRIC.RT.Xfo({
      tr: new FABRIC.RT.Vec3(1.0, 2.0, 3.0)
  }),
  target: new FABRIC.RT.Vec3(10.0, 0.0, 0.0)
});</programlisting>
      <para>The upvector direction used for the AimTransform is always the positive Y axis.</para>
    </section>
  </section>
  <section>
    <title>Animation Guide</title>
    <para><inlinemediaobject>
        <imageobject>
          <imagedata fileref="images/sg_animation_01.png" width="60%"/>
        </imageobject>
      </inlinemediaobject></para>
    <para>The animation pipeline in Fabric Engine's SceneGraph is heavily inspired by the animation
      systems commonly found in game engines. The SceneGraphNodes in the animation pipeline
      are:</para>
    <itemizedlist>
      <listitem>
        <para><emphasis role="bold">AnimationController</emphasis></para>
      </listitem>
      <listitem>
        <para><emphasis role="bold">TrackAnimationContainer</emphasis></para>
      </listitem>
      <listitem>
        <para><emphasis role="bold">CharacterAnimationContainer</emphasis></para>
      </listitem>
    </itemizedlist>
    <para>The actual evaluation of the animation is done in KL operators on the target nodes. In the
      image above the animation is driving a transform node, but any node can be driven by animation
      in Fabric Engine's SceneGraph.</para>
    <section>
      <title>The Animation Controller node</title>
      <para>An Animation Controller is responsible for computing a time value from given inputs.
        This allows to simulate the time in a controller, loop or ping-pong the time or do any kind
        of manipulation on the time inside the controller. A single controller can be used by many
        evaluators. The default Animation Controller node is bound to the globals SceneGraph node
        storing the global scene time.</para>
      <programlisting language="JavaScript">var controller = scene.constructNode('AnimationController', {
  timeRange: new FABRIC.RT.Vec2(0.0, 10.0), // ten seconds
  outOfRange: 1 // looping
});</programlisting>
    </section>
    <section>
      <title>The TrackAnimationContainer</title>
      <para>Both the <emphasis role="bold">TrackAnimationContainer</emphasis> as well as the
          <emphasis role="bold">CharacterAnimationContainer</emphasis> inherit from the <emphasis
          role="bold">AnimationContainer</emphasis>. The AnimationContainer SceneGraph node
        represents a container for any kind of animation. The TrackAnimationContainer uses a sliced
        dependency graph node to store many animation tracks in a single node. All tracks on the
        TrackAnimationContainer have to contain the same type of keys, which is why you can't
        construct a TrackAnimationContainer as is, you need to instantiate inherited nodes of it,
        such as the <emphasis role="bold">LinearTrackAnimationContainer</emphasis> containing linear
        keys or <emphasis role="bold">BezierTrackAnimationContainer</emphasis> containing bezier
        keys.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_animation_02.png" width="30%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The TrackAnimationContainer represents a single animation using multiple tracks. The
        benefit of the TrackAnimationContainer is that tracks are stores in slices, and processing
        on the tracks can happen in a multi-threaded fashion.</para>
      <programlisting language="JavaScript">var linearkey = function(time, value){ return new FABRIC.RT.LinearKeyframe(time, value); };

var trackContainer = scene.constructNode('LinearTrackAnimationContainer', {});

trackContainer.addTrack(new FABRIC.RT.LinearKeyframeTrack('tr.x', FABRIC.RT.rgb(1, 0, 0), [
  linearkey(0, 0), linearkey(50, 0), linearkey(75, 50), linearkey(100, 0)
]));
trackContainer.addTrack(new FABRIC.RT.LinearKeyframeTrack('tr.y', FABRIC.RT.rgb(0, 1, 0), [
  linearkey(0, 0), linearkey(50, 10), linearkey(75, 00), linearkey(100, 0)
]));
trackContainer.addTrack(new FABRIC.RT.LinearKeyframeTrack('tr.z', FABRIC.RT.rgb(0, 0, 1), [
  linearkey(0, 0), linearkey(50, 30), linearkey(75, 00), linearkey(100, 30)
]));</programlisting>
      <para>The code above create a small helper function for creating a linear key frame, then the
        track animation container is created. Once the container exists tracks can be pushed to it,
        providing the name of the track, a color for the UI as well as an array of keys for the
        track.</para>
    </section>
    <section>
      <title>The CharacterAnimationContainer</title>
      <para>The <emphasis role="bold">CharacterAnimationContainer</emphasis> on the other hand is
        quite different from the TrackAnimationContainer. It stores a complete animation containing
        several tracks per slice, allowing to store a large number of complete animations on a
        single node. This container can be understood as a library of animations. Each animation is
        stored as a <emphasis role="bold">TrackSet</emphasis>, which is essentially an array of
        tracks as well as a name for the TrackSet.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_animation_03.png" width="70%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The CharacterAnimationContainer is used for the character pipeline, and will be
        discussed in more detail in the characters related section of this document. Essentially
        though, this is how you create a CharacterAnimationContainer:</para>
      <programlisting language="JavaScript">var linearkey = function(time, value){ return new FABRIC.RT.LinearKeyframe(time, value); };

var characterContainer = scene.constructNode('LinearCharacterAnimationContainer', {});

var walking = characterContainer.newTrackSet('walking');
walking.tracks.push(new FABRIC.RT.LinearKeyframeTrack('tr.x', FABRIC.RT.rgb(1, 0, 0), [
  linearkey(0, 0), linearkey(50, 0), linearkey(75, 50), linearkey(100, 0)
]));
walking.tracks.push(new FABRIC.RT.LinearKeyframeTrack('tr.y', FABRIC.RT.rgb(0, 1, 0), [
  linearkey(0, 0), linearkey(50, 10), linearkey(75, 00), linearkey(100, 0)
]));
walking.tracks.push(new FABRIC.RT.LinearKeyframeTrack('tr.z', FABRIC.RT.rgb(0, 0, 1), [
  linearkey(0, 0), linearkey(50, 30), linearkey(75, 00), linearkey(100, 30)
]));

characterContainer.addTrackSet(walking, [0,1,2]);</programlisting>
    </section>
    <section>
      <title>Binding animation to target nodes</title>
      <para>To use the animation on a target node, such as a transform node, for example, you can
        call the <emphasis role="bold">bindNodeMembersToTracks</emphasis> method of the animation
        container. You need to specify the target binding which includes the name of the member on
        the target node as well as the tracks that need to be bound to it. This you can drive
        complex types, as as a <emphasis role="bold">Vec3</emphasis> for example, you can bind
        multiple tracks to the same member. In the case of a Vec3 the first track will go to the x
        component, the second track to the y component and so on.</para>
      <programlisting language="JavaScript">trackContainer.bindNodeMembersToTracks(transform, {
  'globalXfo.tr': [0, 1, 2] // representing the tracks tr.x, tr.y and tr.z
}, controller);</programlisting>
      <para>Binding the animation on the target node will create an operator on the target's
        dependency graph node which evaluates the animation provided in the animation container and
        writes to the target node's member data. The operator also binds in the animation controller
        which was used during the construction of the animation container. If you don't provide a
        controller to the bindNodeMembersToTracks method the generated operator will simply bind to
        the global time. So in the case discussed in the code snippets in the animation guide, the
        resulting graph will look like this:</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_animation_04.png" width="80%"/>
          </imageobject>
        </inlinemediaobject></para>
    </section>
  </section>
  <section>
    <title>Geometry Guide</title>
    <para>The geometry hierarchy in Fabric Engine's SceneGraph follows a classical inheritance
      model. Each node in the hierarchy adds functionality the the constructed SceneGraph node.
      Geometry can be created in several ways:</para>
    <para><inlinemediaobject>
        <imageobject>
          <imagedata fileref="images/sg_geometry_01.png" width="75%"/>
        </imageobject>
      </inlinemediaobject></para>
    <para>1. A base geometry type can be constructed, and its geometry data can be populated from
      JavaScript:</para>
    <programlisting language="JavaScript">var geometryNode = scene.pub.constructNode('Triangles');
geometryNode.loadGeometryData({
  positions: [FABRIC.RT.vec3(0, 0, 0), FABRIC.RT.vec3(0, 0, 1.0), FABRIC.RT.vec3(1.0, 0, 0)], 
  indices: [0, 1, 2]
}); </programlisting>
    <para>2. Geometry can be constructed by loading an external resource file, such as an OBJ file,
      for example:</para>
    <programlisting language="JavaScript">scene.importAssetFile('Models/cow.obj',{ splitMaterials: true } );</programlisting>
    <para>3. A primitive can be constructed. The primitive constructor assigns geometry generation
      operators which create all of the vertices and other data such as normals based on options on
      the primitive.</para>
    <programlisting language="JavaScript">var primitiveNode = scene.constructNode('Circle', { radius: 7 });</programlisting>
    <section>
      <title>Anatomy of a Geometry Node</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_geometry_02.png" width="40%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>A geometry SceneGraphNode contains several dependency graph nodes. Fabric Engine's
        slicing scheme is used to represent the data, and to allow high performance operations such
        as deformation on the geometry using multi-threading.</para>
      <para>The <emphasis role="bold">Uniforms</emphasis> node stores single values that are
        associated with the geometry, but don't vary per component. Primitives assign uniform values
        that are often exposed from the scene graph node as modifiable parameters. Triangles and
        Lines also store an array of Integers on the Uniforms node called <emphasis role="bold"
          >indexList</emphasis> which defines the connectivity of points for lines and
        triangles.</para>
      <para>The <emphasis role="bold">Attributes</emphasis> node stores all the ‘per-component’
        information. Attributes can easily be added and removed from geometry by simply adding and
        removing members from this node. The Attributes node is sliced, so the number of slices
        matches the number of vertices, for example.</para>
      <para>The <emphasis role="bold">BoundingBox</emphasis> node is generated using the attributes,
        and is used to accelerate interaction with the geometry such as raycasting.</para>
    </section>
    <section>
      <title>Geometry Generation</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_geometry_03.png" width="40%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Note: this are will be re-structured slightly once we have support for node
        nesting.</para>
      <para>The purpose of a generator operator is to generate the vertex information that is stored
        in the attributes node, and the indexList (for Triangles and Lines), which is stored in the
        ‘Uniforms’ node. First we calculate the number of vertices in the <emphasis role="bold"
          >setCount</emphasis> operator, and then populate the attributes node in the second
        operator. The second operator also writes the indexList which is stored on the Uniforms
        node.</para>
    </section>
    <section>
      <title>Geometry Services</title>
      <para>A key service that the the Geometry node provides is integration with the rendering
        pipeline. The design of Fabric Engine's SceneGraph is based heavily on OpenGL shading
        language GLSL, and all rendering in the OpenGL viewport is performed via shaders. </para>
      <para>The geometry node constructs an event handler and binds operators to it for loading all
        the various vertex attributes into the GPU and storing the buffer ids. This means that you
        can add a new vertex attributes to a geometry, then use that data in a shader and the
        geometry node will take care of loading the data so it is ready for the shader. This is
        discussed in more detail in the <emphasis role="bold">Drawing Pipeling Guide</emphasis>
        section of this document.</para>
    </section>
    <section>
      <title>Geometry Data Copies</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_geometry_04.png" width="60%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Geometry data copies provide a way to split the definition of a rendered geometry into
        multiple sections. A Geometry data copy is used to extend a base geometry, usually by adding
        deformation operators. The base geometry represents the original undeformed geometry, and
        the data copy is used to apply changes. The Geometry data copy contains only members
        required for the modification. During rendering, uniforms and attributes are loaded from the
        base geometry and the data copy.</para>
      <para>Since the Attributes node is sliced, deformation can be performed using
        multi-threading.</para>
      <programlisting language="JavaScript">var geometryCopyNode = scene.constructNode('GeometryDataCopy', {baseGeometryNode: geometryNode} );
geometryCopyNode.addVertexAttributeValue('positions', 'Vec3', { genVBO:true, dynamic:true } );</programlisting>
      <para>Note: The <emphasis role="italic">PerPointDeformation.html</emphasis> sample application
        contains an example of this.</para>
    </section>
  </section>
  <section>
    <title>Parsers Guide</title>
    <para>Fabric Engine's SceneGraph comes with several parsers for importing external resource
      files. Since the loading of external data happens asynchronously, you will need to provide
      callback functions to the parsers, which will executed once the content is loaded, parsed and
      ready for use. Parsers are automatically invoked and chosen based on the file extension of the
      resource to load.</para>
    <section>
      <title>The OBJ Parser</title>
      <para>The OBJ file format can store polygonal meshes with UV coordinates as well as basic
        material settings. You can use the OBJ parser like this:</para>
      <programlisting language="JavaScript">scene.importAssetFile('Models/cow.obj', {splitMaterials: false}, function(assetNodes) {
  for(var name in assetNodes) {
    console.log(assetNodes[name]);
  }
});</programlisting>
      <para>The last argument to the <emphasis role="bold">importAssetFile</emphasis> method is the
        function to execute once the parsed result is ready for consumption. The OBJ parser returns
        a dictionary of triangle geometry nodes representing all of the geometries which are part of
        the OBJ file. If the <emphasis role="bold">splitMaterials</emphasis> option is set to true,
        the polygon material assignments of the OBJ file will further split the meshes, to enable
        the SceneGraph's drawing pipeline to render them with separate shaders.</para>
      <para>Note: The <emphasis role="italic">ModelViewer.html<emphasis role="bold"
          > </emphasis></emphasis>sample application contains an example of the OBJ parser in
        use.</para>
    </section>
    <section>
      <title>The Collada Parser</title>
      <para>Collada's DAE file format can store complex types of data, including polygonal meshes,
        transform hierarchies, point clouds as well as other complex 3D data structures. The
        SceneGraph's collada parser currently supports:<itemizedlist>
          <listitem>
            <para>Polygonal Meshes including UV coordinates and skinning weights, imported as
              Triangles nodes</para>
          </listitem>
          <listitem>
            <para>Character Hierarchies used for skinning, imported as CharacterRig nodes</para>
          </listitem>
          <listitem>
            <para>FCurve animation on hierarchies, imported as CharacterAnimationContainer
              nodes</para>
          </listitem>
          <listitem>
            <para>Cameras including focal length and aperture settings, imported as Camera
              nodes</para>
          </listitem>
        </itemizedlist></para>
      <para>The Collada parser can be deployed like this:</para>
      <programlisting language="JavaScript">scene.importAssetFile('Models/character.dae', {
    constructRigFromHierarchy: true
}, function(assetNodes) {
  for(var name in assetNodes) {
    console.log(assetNodes[name]);
  }
});</programlisting>
      <para>The last argument of the parser's invocation is a function to be called once the collada
        data is parsed and ready for consumption. In the example above we simply log the data to the
        console. For further details on the character related nodes please see the <emphasis
          role="bold">Character Guide</emphasis> section of this document.</para>
      <para>Note: The <emphasis role="italic">CharacterSkeleton.html<emphasis role="bold"
          > </emphasis></emphasis>sample application contains an example of the Collada parser in
        use.</para>
    </section>
    <section>
      <title>The Alembic Parser</title>
      <para>Alembic ABC file format can store several kinds of data. The SceneGraph's Alembic
        intergration currently supports:<itemizedlist>
          <listitem>
            <para>Polygonal Meshes including UV coordinates and normals, imported as Triangle
              nodes</para>
          </listitem>
          <listitem>
            <para>Curve lists including width and color values, imported as Lines nodes</para>
          </listitem>
          <listitem>
            <para>Cameras with proper focal length and aperture settings, imported as Camera
              nodes</para>
          </listitem>
          <listitem>
            <para>Point clouds including full transform support, color values, imported as Points
              nodes</para>
          </listitem>
        </itemizedlist></para>
      <para>Since Alembic stores animation as discrete samples the parser doesn't load all of the
        data to memory, but rather constructs operators which re-evaluate based on time changes.
        This way animation can be loaded into Fabric Engine and synchronized with the SceneGraph's
        global time or a different AnimationController.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_parsers_01.png" width="80%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The Alembic resource node holds what is called a <emphasis role="bold"
          >AlembicHandle</emphasis> to the original resource file, which is forwarded through the
        dependency graph and used by all of the ABC operators to pull the relevant data out of the
        Alembic file. Per se there is no parsing happening in JavaScript, so once the resource is
        loaded, the <emphasis role="bold">loadSuccess</emphasis> event fires. The sample code below
        shows how to load data from an Alembic resource. For more details on event handling please
        refer to the <emphasis role="bold">Event Guide</emphasis> section of this document.</para>
      <programlisting language="JavaScript">var alembicLoadNode = scene.constructNode('AlembicLoadNode', {
  url: 'Models/cow.abc'
});
alembicLoadNode.addEventListener('loadSuccess', function(){
  var assetNodes = alembicLoadNode.getParsedNodes(); 
  for(var name in assetNodes) {
    console.log(assetNodes[name]);
  }
});</programlisting>
      <para>Note: The <emphasis role="italic">Alembic/Primitives.html<emphasis role="bold"
          > </emphasis></emphasis>sample application contains an example of the Alembic parser in
        use.</para>
    </section>
  </section>
  <section>
    <title>Characters Guide</title>
    <para>This is do be done for Phil!</para>
  </section>
  <section>
    <title>Images and Video Guide</title>
    <para>The SceneGraph supports reading and using external image resource files as well as
      external video streams. Typically images are never loaded onto dependency graph nodes or
      stored in the main memory, they are rather pushed directly to the GPU. When drawing textures
      there is no need to keep the image in the RAM, however if you want to modify the image using
      the CPU the images has to be stored in the dependency graph. Fabric Engine supports 2D images
      as well as 3D images.</para>
    <section>
      <title>Anatomy of an Image node</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_images_01.png" width="40%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Similar to the Geometry node, an image node is split into two dependency graph nodes.
        The <emphasis role="bold">Uniforms</emphasis> node stores all of the non-per-pixel data,
        such as the width and height of the image. These values are typically exposed to the
        SceneGraph node as getter function. The <emphasis role="bold">Attributes</emphasis> node
        contains the per pixel data, however only if the Attributes dependency node is required at
        all. As mentioned above the per pixel data is normally directly pushed to the GPU.</para>
    </section>
    <section>
      <title>Loading 2D Images</title>
      <para>Currently the SceneGraph supports loading 2d images of the types <emphasis role="bold"
          >JPG</emphasis>, <emphasis role="bold">PNG</emphasis>, <emphasis role="bold"
          >BMP</emphasis>, <emphasis role="bold">TIF</emphasis>, <emphasis role="bold"
          >EXR</emphasis>, and <emphasis role="bold">HDR</emphasis>. The last two are stores as
        floating point images, while the other formats are stored as byte images. 2d images are
        always stored as RGBA, even if the original image data doesn't contain an alpha
        channel.</para>
      <programlisting language="JavaScript">var image2D = scene.constructNode('Image2D', {
  url: 'Resources/tomatoes_960_640.png',
  createDgNodes: false
});</programlisting>
      <para>If you want the image to be loaded into the RAM and accessible in the dependency graph,
        you need to set the <emphasis role="bold">createDgNodes</emphasis> option to true. You can
        then attach operators to the Attributes node to perform per pixel calculations in a
        multi-threaded fashion.</para>
      <para>Note: The <emphasis role="italic">BackgroundTexture.html<emphasis role="bold"
          > </emphasis></emphasis>sample application contains a simple example of an image node in
        use.</para>
    </section>
    <section>
      <title>Loading 3D Images</title>
      <para>Currently the SceneGraph only supports loading 3d images of the type <emphasis
          role="bold">NRRD</emphasis>. 3d images are always stored as USHORT with RGBA
        channels.</para>
      <programlisting language="JavaScript">var image3D = scene.constructNode('Image3D', {
  url: 'Resources/threed_texture.nrrd',
  createDgNodes: false
});</programlisting>
      <para>As with 2d iamges, if you want the image to be loaded into the RAM and accessible in the
        dependency graph, you need to set the <emphasis role="bold">createDgNodes</emphasis> option
        to true.</para>
      <para>Note: The <emphasis role="italic">MedicalImaging.html<emphasis role="bold"
          > </emphasis></emphasis>use-case application contains an example of a 3d image node in
        use.</para>
    </section>
    <section>
      <title>Loading Video</title>
      <para>Video nodes are pretty much the same as Image2D nodes, except that they have operators
        attached which pull frames out of the external video file resource. For that, the current
        frame is stored on the Attributes dependency graph node and is constantly pushed to the GPU
        if the time of the video changes. Fabric Engine utilizes the <emphasis role="bold"
          >FFMPEG</emphasis> library to offer support for a wide variety of video formats. Aside
        from other formats, the SceneGraph's video node supports: <emphasis role="bold"
          >AVI</emphasis>, <emphasis role="bold">MOV</emphasis> and <emphasis role="bold"
          >MP4</emphasis>. </para>
      <programlisting language="JavaScript">var videoNode = scene.constructNode('Video', {
  url: 'Resources/bee_960.mov',
  loop: true
});</programlisting>
      <para>Note: The <emphasis role="italic">Video.html<emphasis role="bold"
          > </emphasis></emphasis>sample application contains a simple example of a video node in
        use.</para>
    </section>
  </section>
  <section>
    <title>Drawing Pipeline Guide</title>
    <para>Fabric Engine's SceneGraph's drawing pipeline is very flexible and customizable. Drawing
      is performed with as few operations as possible providing high performance rendering.
      Generally is is important to understand that drawing invokes the evaluation of the dependency
      graph.</para>
    <section>
      <title>Predescend and Postdescend</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_drawing_01.png" width="70%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The drawing pipline is implemented using eventhandlers. The eventhandler tree for
        drawing listens to the paint event of the canvas resp. the windows. The drawing pipeline
        evaluates in two phases: the <emphasis role="bold">Predescend</emphasis> and <emphasis
          role="bold">Postdescent</emphasis>. Predescend happens when the drawing pipline evaluates
        each event handler from left to right, resp. from the event down to the last eventhandler.
        Postdescend happens once the descend is done, traveling through the event graph back up to
        the event. Operators for drawing can be applied on either the <emphasis role="bold"
          >preDescendBindings</emphasis> or the <emphasis role="bold"
          >postDescendBindings.</emphasis> When each eventhandler evaluates it pulls on the
        connected dependency graph nodes. If the dependency graph node itself has dependencies and
        operators, the execution of the dependencies and operatos will be fired.</para>
    </section>
    <section>
      <title>Windows</title>
      <para>Each window in Fabric defines a dependency graph node and an Event. The node contains
        data about the window such as its width and height, and the event is fired when painting of
        the window is required. The width and height values are driven by the Fabric plugin, and are
        updated when the window is resized.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_drawing_02.png" width="40%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The Window Event node is an event that is fired whenever the window needs painting. This
        may occur because the window was resized, revealed, or invalidated in any way. It is also
        possible to manually trigger a redraw from JavaScript. Redrawing of the window during
        animation is effected by modifying graph variables such as time, and then manually
        triggering a redraw. The JavaScript mechanism to fire a redraw manually is accessible
        through the <emphasis role="bold">Viewport</emphasis> node.</para>
      <programlisting language="JavaScript">var viewport = scene.constructNode('Viewport', {
  windowElement: document.getElementById('FabricContainer') // provide the HTML element for the viewport
});
// fire a redraw manually
viewport.redraw();</programlisting>
      <para>By attaching event handlers to the Window Paint Event node, we can coordinate the
        drawing of the window using OpenGL. The OpenGL context is set up and bound prior to the
        paint event being fired. For more information on Events, and Event Handlers, please consult
        the Core Programming Guide.</para>
    </section>
    <section>
      <title>Setting up the Viewport in OpenGL</title>
      <para>When the window redraw event is fired, the subgraph is traversed, first visiting the
        Viewport event handler which has an operator attached called <emphasis role="bold"
          >viewPortBeginRender</emphasis>. When viewPortBeginRender is executed, the initial OpenGL
        parameters are set.</para>
      <programlisting language="JavaScript">operator viewPortBeginRender(io Integer width, io Integer height, io Color backgroundColor) {   
  glCullFace(GL_BACK);
  glEnable(GL_DEPTH_TEST);
  glEnable(GL_CULL_FACE);   glViewport(0, 0, width, height);
  glClearColor(backgroundColor.r,
  backgroundColor.g, backgroundColor.b, backgroundColor.a);
  glClear(GL_COLOR_BUFFER_BIT |
  GL_DEPTH_BUFFER_BIT);
}</programlisting>
      <para>The camera event handler is then visited, where the camera projection values are
        computed in the operator <emphasis role="bold">updateCameraProjection</emphasis>.</para>
    </section>
    <section>
      <title>Shaders</title>
      <para>The Fabric SceneGraph rendering system breaks shaders into 2 components, <emphasis
          role="bold">shaders</emphasis> and <emphasis role="bold">materials</emphasis>. The shader
        event handler loads the shader source into the OpenGL driver and compiles the shader
        program. The specification of the shader also includes some meta-data such as the buffers
        required by the shader, and any constant values that must be defined. </para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_drawing_03.png" width="70%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Note: To inspect the drawing pipeline you can use the SceneGraph's debugger. Just open
        the <emphasis role="italic">ModelViewer.html</emphasis> sample application, for example,
        open the JavaScript console, and type:</para>
      <programlisting language="JavaScript">FABRIC.displayDebugger();</programlisting>
    </section>
    <section>
      <title>GLSL Uniforms and Attributes</title>
      <para>GLSL shaders define a set of parameters which must be filled out before the geometry can
        be drawn on screen. These 2 sets of requirements are stored in 2 arrays called
        attributeValues, and uniformValues. These arrays are accessible by all child event handlers
        who can determine what data is required by the shader.</para>
      <para>
        <emphasis role="italic">Note: the design of the event handler graph means that 2 different
          nodes can define the same data under the same 'scope name', and the order of visitation
          defines which scope is valid. This enables a single geometry to be rendered multiple times
          using different shaders.</emphasis>
      </para>
    </section>
    <section>
      <title>Materials</title>
      <para>Materials define parameters for the shader program and is used to attach image loaders.
        The Material node in Fabric Engine is generated using meta data associated with the shader.
        XML files are loaded which contain both the GLSL shader code, and meta data that instructs
        the rendering system how to construct material node instances.</para>
      <para>Materials provide data to the shader such as shading parameters, and also provide a
        branch point in the event graph where textures can be loaded and bound prior to traversal
        continuing to the Instance node.</para>
    </section>
    <section>
      <title>Textures</title>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_drawing_04.png" width="60%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Materials which utilize textures must specify which <emphasis role="bold"
          >textureUnit</emphasis> to assign each texture. This process is automated using the
        material system in the SceneGraph. For each textureUnit, a <emphasis role="bold"
          >stub</emphasis> node is generated. This stub node binds in the texture unit that will be
        assigned to the texture. This allows multiple textures to be used on the same material, and
        textures to be shared amongst materials. </para>
    </section>
    <section>
      <title>Instances</title>
      <para>The <emphasis role="bold">instance</emphasis> node represents a drawn piece of geometry.
        To be able to draw geometry on screen, several things bust have happened prior to the draw
        call.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_drawing_05.png" width="60%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Geometry rendering happens in the following order:<orderedlist>
          <listitem>
            <para>The shader program is loaded</para>
          </listitem>
          <listitem>
            <para>The the material node is traversed and shader constants set</para>
          </listitem>
          <listitem>
            <para>From the material traversal may continue into the texture stubs and on into the
              texture nodes where the textures are loaded. </para>
          </listitem>
          <listitem>
            <para>From the material node, traversal continues down to the instance node, where the
              matrix for the draw is loaded.</para>
          </listitem>
          <listitem>
            <para>From the instance node, traversal continues down to the geometry node where the
              geometry buffers are loaded and shader uniforms may also be set.</para>
          </listitem>
          <listitem>
            <para>The Geometry is a leaf node, and after the preDescendBindings have been evaluated
              the postDescendBindings follow immediately, and the draw call is executed.</para>
          </listitem>
        </orderedlist></para>
    </section>
    <section>
      <title>Shadows</title>
      <para>Shadow maps are rendered in a pre-draw stage prior to the camera render pass. For each
        light, we render the scene from the point of view of the light, and store the depth
        information in a depth buffer. The depth buffer ID is stored in the light node which is also
        bound to the material. This gives the material access to the lights shadow buffers, enabling
        the correct shadowing of geometry.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_drawing_06.png" width="90%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>The red arrow in the diagram represents a binding from the light to the material. This
        binding is what gives the material access to the light's shadow buffer.</para>
    </section>
  </section>
  <section>
    <title>Deferred Rendering Guide</title>
    <para>Deferred rendering describes the process of drawing the viewport's content to several
      framebuffers, and then doing additional passes of rendering utilizing these framebuffers.
      Deferred rendering is tremendously different from standard rendering, since all of the GLSL
      shaders have to store their resulting pixel values into framebuffers. So shaders have to be
      specifically written for deferred rendering.</para>
    <para><inlinemediaobject>
        <imageobject>
          <imagedata fileref="images/sg_deferred_01.png" width="90%"/>
        </imageobject>
      </inlinemediaobject></para>
    <para>Deferred rendering allows to perform 2D post effects on the GPU, or additional 3D
      rendering as a post effect.</para>
    <para>Note: The <emphasis role="italic">ToonRendering.html</emphasis> sample applications
      contains an example of using the deferred renderer.</para>
    <section>
      <title>Setting up the Deferred Renderer</title>
      <para>The SceneGraph provides a utility node called the <emphasis role="bold"
          >BasicDeferredRenderer</emphasis>. </para>
      <programlisting language="JavaScript">var renderer = scene.constructNode('BasicDeferredRenderer', {
  addDepth: false, // don't add a depth framebuffer
  colorBuffers: [{name: 'diffuseA, nbChannels: 4}, {name: 'diffuseB', nbChannels: 4}]
});</programlisting>
      <para>Once the renderer is setup, you can setup materials through it. This will ensure that
        the shader and material eventhandlers are connected up correctly within the drawing
        pipeline. You can create <emphasis role="bold">prePassMaterials</emphasis> (for the initial
        draw into framebuffers) or <emphasis role="bold">postPassMaterials</emphasis> (for the
        deferred draw utilizing the framebuffers).</para>
      <programlisting language="JavaScript">var drawMaterial = renderer.addPrePassMaterial('MyDeferredShader', {});
var compositingMaterial = renderer.addPostPassMaterial('MyCompositingShader', {});</programlisting>
    </section>
    <section>
      <title>PrePass Deferred Shaders</title>
      <para>Shaders for a deferred rendering pipline have to write their results in the fragment
        data in GLSL. This will fill the framebuffers. You need to setup the framebuffers
        accordingly when constructing the deferred renderer node. Prepass deferred shaders replace
        the standard shaders from a non-deferred drawing pipeline. Here's an example of a small
        fragment shader that writes red to the first and blue to the second framebuffer.</para>
      <programlisting language="JavaScript">void main(){
  gl_FragData[0] = vec4(1.0,0.0,0.0,1.0);
  gl_FragData[1] = vec4(0.0,0.0,1.0,1.0);
}</programlisting>
    </section>
    <section>
      <title>PostPass Deferred Shaders</title>
      <para>PostPass deferred shaders perform the <emphasis role="bold">compositing</emphasis> of
        the framebuffers to the final displayed image. Typically postpass shaders perform per pixel
        compositing, but they can access all pixels of the framebuffers, since the framebuffers are
        stored as textures on the GPU. Here's an example of a fragment shader which combines both
        diffuse color from the deferred renderer above:</para>
      <programlisting language="JavaScript">uniform sampler2D u_samplerDiffuseA;
uniform sampler2D u_samplerDiffuseB;

void main(){
  vec2 windowCoord = gl_TexCoord[0].st*0.5+0.5;
  gl_FragColor = texture2D( u_samplerDiffuseA, windowCoord ) + texture2D( u_samplerDiffuseB, windowCoord ); 
}</programlisting>
      <para>This will result in a violet rendering of the 3D scene, combined from two different draw
        results.</para>
      <para>Note: Please also see the <emphasis role="italic">DeferredRendering.html</emphasis>
        sample application for an example of a more advanced scenario.</para>
    </section>
  </section>
  <section>
    <title>SceneGraph IO Guide</title>
    <para>Waiting for Jerome's input...!</para>
  </section>
  <section>
    <title>Events Guide</title>
    <para>The SceneGraph provides a system for automatically firing callbacks when certain things
      happen. SceneGraph events are a very powerful mechanism to automate functionality, especially
      since in web applications things can happen asynchronously.</para>
    <section>
      <title>Setting up a node for event handling</title>
      <para>To enable events on a SceneGraph node the <emphasis role="bold"
          >addEventHandlingFunctions</emphasis> method has to be called in the constructor of the
        node.</para>
      <programlisting language="JavaScript">scene.addEventHandlingFunctions(myNodePrivateInterface);</programlisting>
      <para>Once that's done the node can fire events and receive event callbacks. To attach a
        callback to the node, other nodes resp. the scene script can call the <emphasis role="bold"
          >addEventListener</emphasis> method.</para>
      <programlisting language="JavaScript">var myCallback = function(evt) {
  console.log(evt);
  return 'remove';
};
myNodePublicInterface.addEventListener('myEvent', myCallback);</programlisting>
      <para>If the event callback function returns <emphasis role="italic">'remove'</emphasis> the
        callback will be removed from the event listener stack, and won't fire again if the element
        fires another time. If you don't return <emphasis role="italic">'remove'</emphasis> the
        callback will stay attached.</para>
      <para>You can also remove the event callback by calling the <emphasis role="bold"
          >removeEventListener</emphasis> method, which allows to have functions listens to event
        dynamically. So to say you can attach functions and de-attach them again.</para>
      <programlisting language="JavaScript">myNodePublicInterface.removeEventListener('myEvent', myCallback);</programlisting>
      <para>To trigger the event programatically you can call the <emphasis role="bold"
          >fireEvent</emphasis> method on the node. </para>
      <programlisting language="JavaScript">myNodePublicInterface.fireEvent('myEvent', { data: 'myData' });</programlisting>
      <para>This fires all attached event callbacks, and provides the event data to each of the
        callback functions.  This mechasnism is used heavily throughout the SceneGraph.</para>
    </section>
    <section>
      <title>loadSuccess event</title>
      <para>The <emphasis role="bold">ResourceLoadNode</emphasis>, covered in the <emphasis
          role="bold">SceneGraph IO Guide</emphasis> in this document, uses events to dispatch the
        call of event listeners once a resource file is loaded. This mechanism is uses in the
        SceneGraph parsers, but you can also use it for custom scenarios like this:</para>
      <programlisting language="JavaScript">var resourceLoadNode = scene.constructNode('ResourceLoad', {
  url: 'myBinaryFile.bin'
});
resourceLoadNode.addEventListener('loadSuccess', function(evt){
  // attach operators to the resourceLoadNode for parsing...
  return 'remove';
});</programlisting>
      <para>This allows you to automatically continue with the setup of the application once the
        resource file is downloaded and ready.</para>
    </section>
  </section>
  <section>
    <title>Selection Manager Guide</title>
    <para>The SceneGraph comes with a manager for selection, called the <emphasis role="bold"
        >SelectionManager</emphasis>. This manager is the basic implementation, and simply keeps
      track of a collection of selected nodes. It provides the <emphasis role="bold"
        >selectionChanged</emphasis> event for automating UI changes, for example, based on the
      selection.</para>
    <section>
      <title>Basic Selection Management</title>
      <para>The code snippet below sets up the manager, attached a callback to it and selects as
        well as deselects a single node. This code is the basis for more complex selection
        management.</para>
      <programlisting language="JavaScript">// setup manager and attach event callback
var selectionMgr = scene.constructManager('SelectionManager');
selectionMgr.addEventListener('selectionChangesd',function(evt) {
  console.log(evt.selection);
});

// select a node and deselect it again
selectionMgr.addToSelection(myNode);
selectionMgr.removeFromSelection(myNode);</programlisting>
    </section>
    <section>
      <title>Viewport Selection Manager</title>
      <para>The <emphasis role="bold">ViewportSelectionManager</emphasis> works by providing a new
          <emphasis role="bold">Instance</emphasis> node, called the <emphasis role="bold"
          >SelectableInstance</emphasis>. It contains a selection state as well as an additional
        material, that indicates the selection during drawing.</para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_selection_01.png" width="70%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>When a SelectableInstance node is hovered, the material on the node changes to the
          <emphasis role="italic">highlighted</emphasis> material. Once the node is selected the
        material changes to the <emphasis role="italic">selected</emphasis> material. </para>
      <programlisting language="JavaScript">// create the materials
var normalMaterial = scene.constructNode('FlatMaterial', { color: FABRIC.RT.rgb(0.0, 0.0, 1.0, 1) });
var highlightMaterial = scene.constructNode('FlatMaterial', { color: FABRIC.RT.rgb(0.7, 0.7, 0.7, 1) });
var selectedMaterial = scene.constructNode('FlatMaterial', { color: FABRIC.RT.rgb(1.0, 0.0, 0.0, 1) });

// create a selectable instance
var myInstance = scene.constructNode('SelectableInstance', {
  transformNode: myTransform,
  geometryNode: myGeometry,
  materialNode: normalMaterial,
  highlightMaterial: highlightMaterial,
  selectMaterial: selectedMaterial
});

// setup manager and attach event callback
var selectionMgr = scene.constructManager('ViewportSelectionManager');
selectionMgr.addEventListener('selectionChangesd',function(evt) {
  console.log(evt.selection);
});

// select a node and deselect it again
selectionMgr.addToSelection(myInstance);
selectionMgr.removeFromSelection(myInstance);</programlisting>
      <para><emphasis role="italic">Note: The Selection.html sample application contains an example
          of how to use selection in the SceneGraph.</emphasis></para>
    </section>
    <section>
      <title>Selection Manipulation Manager</title>
      <para>The <emphasis role="bold">SelectionManipulationManager</emphasis> provides an additional
        mechanism for selection based manipulation. For further details on the way manipulation
        works in the SceneGraph please refer to the <emphasis role="bold">Manipulation
          Guide</emphasis> in this document. The SelectionManipulationManager itself is not taking
        care of the selection management, therefore you need to specify the SelectionManager during
        its construction. The SelectionManipulationManager just takes care of setting up a group
        manipulation, that toggles on and off based on selection changes as well as centers the
        manipulator in the center of the selected objects.</para>
      <programlisting language="JavaScript">var manipulationMgr = scene.constructManager('SelectionManipulationManager', {
  selectionManager: selectionMgr,
  manipulators: undefined // here you can specify an array of manipulators to manage
});</programlisting>
      <para>By providing a list of manipulators to the <emphasis role="italic"
          >manipulators</emphasis> option, you can define the kind of manipulations you want the
        manager to take care of. If you don't specify anything, the manipulation will default to to
        a screen space translation.</para>
    </section>
  </section>
  <section>
    <title>Manipulation Guide</title>
    <para>The SceneGraph provides a solid framework for manipulation. While a series of transform
      manipulators are provided, you can build your own manipulators. This document includes a
        <emphasis role="bold">Tutorial for building a custom manipulator</emphasis>.</para>
    <para>Manipulation in the SceneGraph works by modifying the dependency graph's data in
      JavaScript. For this, several steps of execution are required:<orderedlist>
        <listitem>
          <para>On MouseDown: Gather all of the current relevant values (snapshot) and attach event
            callbacks for MouseMove</para>
        </listitem>
        <listitem>
          <para>On MouseMove: Compare current values with the snapshot and change the graph
            accordingly</para>
        </listitem>
        <listitem>
          <para>On MouseUp: Remove the MouseMove event callbacks.</para>
        </listitem>
      </orderedlist></para>
    <section>
      <title>Setting up a Manipulator</title>
      <para>Manipulators require <emphasis role="bold">RayCasting</emphasis> to be enable in the
        viewport, since it needs to determine which objects are hit below the mouse's position. To
        enable RayCasting, provide the following options when constructing the viewport:</para>
      <programlisting language="JavaScript">var viewport = scene.constructNode('Viewport', {
  windowElement: document.getElementById('FabricContainer'),
  enableRaycasting: true,
  rayIntersectionThreshold: 0.8
});</programlisting>
      <para>Manipulators operate on Instance nodes, so you first have to create an instance node to
        be able to attach a manipulator. Manipulators can operate on any member on any dependency
        graph node, but since typically manipulation in 3D affects the transforms of objects, all of
        the provided manipulators in the SceneGraph operate on the <emphasis role="bold"
          >globalXfo</emphasis> member of the transform node.</para>
      <programlisting language="JavaScript">// create an instance out of geometry, transform and material
var instance = scene.constructNode('Instance', {
  geometryNode: myGeometry,
  transformNode: myTransform,
  materialNode: myMaterial
});

// create a manipulator for the instance node
var manipulator = scene.constructNode('3AxisTranslationManipulator', {
  targetNode: instance,
  size: 10,
  linearTranslationManipulators: true,
  planarTranslationManipulators: true,
  screenTranslationManipulators: true
});</programlisting>
      <para>For a list of all of the manipulators available and their options please refer to the
          <emphasis role="bold">SceneGraph Node Reference</emphasis> in this document.</para>
      <para><emphasis role="italic">Note: The Manipulators.html sample application contains an
          example of how to use manipulation in the SceneGraph.</emphasis></para>
    </section>
  </section>
  <section>
    <title>Undo / Redo Guide</title>
    <para>Undo and Redo functionality in the SceneGraph can be achieved by constructing the
        <emphasis role="bold">UndoManager</emphasis> and pusing <emphasis role="bold"
        >Transactions</emphasis> to it. A transaction is a dictionary containing callbacks for
        <emphasis role="bold">onClose</emphasis>, <emphasis role="bold">onUndo</emphasis> and
        <emphasis role="bold">onRedo</emphasis>. The SceneGraph's manipulation system provides these
      kinds of transactions already, but you can implement your own.</para>
    <para>To undo or redo a transaction, simply call the on the <emphasis role="bold"
        >undo</emphasis> and <emphasis role="bold">redo</emphasis> methods of the  of the
      UndoManager.</para>
    <programlisting language="JavaScript">// create an undo manager
var undoMgr = scene.constructManager('UndoManager');

// create a value to be changed
var value = 10;
var prevValue = value;
var newValue;

// push a transaction to it
undoMgr.addTransaction({
  onClose: function() {
    newValue = value;
  },
  onUndo: function() {
    value = prevValue;
  },
  onRedo: function() {
    value = newValue;
  }
});

// change the value
value = 20;

// close the transaction
undoMgr.closeTransaction();

// undo the change
undoMgr.undo();</programlisting>
    <para><emphasis role="italic">Note: The Undo.html sample application contains an example of how
        to use Undo and Redo in the SceneGraph.</emphasis></para>
    <section>
      <title>Using Undo and Redo with Manipulation</title>
      <para>The manipulation system already support undo. Since you can have multiple UndoManagers
        in an application, you can optionally provide the UndoManager to the construction options of
        the manipulators, but even if you didn't specify it the first created undomanager will be
        used for manipulation.</para>
      <programlisting language="JavaScript">// create an undo manager
var undoMgr = scene.constructManager('UndoManager');

// create a manipulator for the instance node
var manipulator = scene.constructNode('3AxisTranslationManipulator', {
  targetNode: instance,
  size: 10,
  linearTranslationManipulators: true,
  planarTranslationManipulators: true,
  screenTranslationManipulators: true,
  undoManager: undefined // optionally you can specify it here, in case you have more than one
});</programlisting>
    </section>
  </section>
  <section>
    <title>Websockets Guide</title>
    <para>The SceneGraph provides an easy way of using websockets to automate client - server -
      client communication. For this a node websocket server is required. For a sample
      implementation, please see our github project
        <link>https://github.com/fabric-engine/websocket-server</link>.</para>
    <para>For test scenarios you might as well use node websocket server located at
        <link>ws.fabric-engine.com</link>.</para>
    <section>
      <title>WebSocketManager</title>
      <para>Before you can send or receive messages you need to setup the <emphasis role="bold"
          >WebSocketManager</emphasis>. Each session uses a unique key, which is determined
        automatically, however you can specify it yourself to ensure that all users of the
        application are able to communicate with each other. </para>
      <para><inlinemediaobject>
          <imageobject>
            <imagedata fileref="images/sg_websockets_01.png" width="40%"/>
          </imageobject>
        </inlinemediaobject></para>
      <para>Since the web socket connection has to be established before message handlers can be
        setup, the constructor also takes in the <emphasis role="bold">onOpenCallBack</emphasis>
        option, which is executed once the connection is up.</para>
      <programlisting language="JavaScript">// create a web socket manager
var websocketMgr = scene.constructManager('WebSocketManager', {
  serverUrl: 'ws.fabric-engine.com',
  contextID: 'myOwnCustomKey',
  onOpenCallBack: function() {
    console.log('Connection established');
  }
});</programlisting>
    </section>
    <section>
      <title>Sending Messages</title>
      <para>To send message, ensure that the connection has been established. Otherwise the sending
        of the message will fail. Messages contain a name, data as well as an optional recipient. If
        you don't specify the recipient the message will be send to all of the participants of the
        current session.</para>
      <programlisting language="JavaScript">websocketMgr.sendMessage('askQuestion', { question: 'What\'s your name?' });</programlisting>
      <para>The data can contain any JSON compliant struct. The WebSocketManager encodes it and
        decodes it automatically.</para>
    </section>
    <section>
      <title>Receiving Messages</title>
      <para>To receive messages you need to setup callbacks for each message type on the
        WebSocketManager. Reception message callbacks themselves can also send messages again of
        course.</para>
      <programlisting language="JavaScript">// setup a message callback for the 'askQuestion' message
websocketMgr.addMessageCallBack('askQuestion', function(message) {
  if(message.data.question == 'What\'s your name?') {
    // reply just to the sender of this message
    var data = {
      question: message.data.question,
      answer: 'My name is Fabric.'
    };
    websocketMgr.sendMessage('replyToQuestion', data, message.sourceID);
  } else
    console.log('I don\'t know how to answer this question: '+message.data.question);
});

// setup a message callback for the 'replyToQuestion' message
websocketMgr.addMessageCallBack('replyToQuestion', function(message) {
  console.log('I asked: '+message.data.question);
  console.log(message.sourceID+' replied: '+message.data.answer);
});</programlisting>
      <para><emphasis role="italic">Note: The WebSockets.html sample application demonstrates how to
          synchronize camera manipulation between clients.</emphasis></para>
    </section>
  </section>
</article>
